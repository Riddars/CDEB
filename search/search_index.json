{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"CDEB: Chemical Data Extraction Benchmark","text":"<p>A multimodal benchmark for evaluating machine learning models that extract structured chemical data from scientific literature.</p>"},{"location":"index.html#about-the-project","title":"About the Project","text":"<p>CDEB (Chemical Data Extraction Benchmark) is a curated benchmark suite aimed at assessing and improving the performance of AI systems in extracting structured chemical information from scientific articles across multiple modalities: text, tables, and figures.</p> <p>The benchmark covers diverse chemical topics, including nanomaterials, small-molecule bioactivity, chelate stability, ionic liquids, and pharmaceutical properties.</p> <p>Project Goal</p> <p>Enable reliable and scalable chemical knowledge extraction by combining multimodal data annotation with expert validation, thereby accelerating downstream scientific research.</p>"},{"location":"index.html#_1","title":"Home","text":""},{"location":"index.html#key-features","title":"Key Features","text":"<ul> <li>10 manually annotated datasets across a range of chemical subfields  </li> <li>Over 16,000 structured records extracted from peer-reviewed literature  </li> <li>Multimodal data sources: text passages, tables, chemical diagrams, figures  </li> <li>Provenance and annotation metadata for every data point  </li> <li>Expert-reviewed annotations ensuring high data quality  </li> <li>Standardized evaluation benchmarks for NLP, vision, and multimodal models  </li> </ul>"},{"location":"index.html#why-it-matters","title":"Why It Matters","text":"<p>Despite advances in large language and vision-language models, scientific chemistry lags behind in AI adoption due to the lack of reliable, multimodal, annotated benchmarks.</p> <p>The Solution</p> <p>CDEB closes this gap by providing a transparent, high-quality benchmark for evaluating and training data extraction systems, validated by domain experts.</p>"},{"location":"index.html#how-to-use-cdeb","title":"How to Use CDEB","text":"<ul> <li>Train and test models to extract chemical entities, values, units, and relationships  </li> <li>Compare performance across extraction tasks using a unified evaluation framework  </li> <li>Explore multimodal learning for chemistry-specific document analysis  </li> <li>Use structured chemical data for tasks like toxicity modeling, material design, and reaction planning  </li> </ul>"},{"location":"index.html#site-sections","title":"Site Sections","text":""},{"location":"index.html#overview","title":"Overview","text":"<p>Motivation, annotation pipeline, and an overview of all datasets.</p>"},{"location":"index.html#datasets","title":"Datasets","text":""},{"location":"index.html#nanomaterials","title":"Nanomaterials","text":"<ul> <li>Cytotoxicity Dataset \u2014 Nanoparticle toxicity in mammalian cells  </li> <li>SelTox Dataset \u2014 Nanoparticle toxicity in microbial systems  </li> <li>Synergy Dataset \u2014 Antibiotic\u2013nanoparticle interaction effects  </li> <li>Nanozymes Dataset \u2014 Enzymatic activity of nanozymes  </li> <li>Magnetic Nanomaterials \u2014 Magnetic property extraction  </li> </ul>"},{"location":"index.html#small-molecules","title":"Small Molecules","text":"<ul> <li>Benzimidazole Antibiotics \u2014 Inhibitory concentrations of benzimidazoles  </li> <li>Oxazolidinone Antibiotics \u2014 Activity profiling of oxazolidinones  </li> <li>Chelate Metal Complexes \u2014 Thermodynamic parameters of chelates  </li> <li>Eye Drops \u2014 Corneal permeability and pharmaceutical properties   </li> <li>Cocrystal Photostability \u2014 Stability of pharmaceutical co-crystals</li> </ul>"},{"location":"index.html#methods","title":"Methods","text":"<p>Detailed pipeline for annotation, validation, and benchmarking:</p> <ul> <li>Approach</li> <li>Data Extraction </li> <li>Data Validation </li> <li>Benchmarking </li> </ul>"},{"location":"index.html#guideline","title":"Guideline","text":"<p>Examples for training and evaluating extraction models with CDEB datasets.</p>"},{"location":"index.html#about-the-project_1","title":"About the Project","text":"<p>Team, how to cite the project, version history, and acknowledgments.</p>"},{"location":"index.html#quick-start","title":"Quick Start","text":"<pre><code>from datasets import load_dataset\n\n# Unique dataset identifier on Hugging Face\ndataset_id = \"ai-chem/Nanozymes\"\ndataset = load_dataset(dataset_id)\ndf = dataset[\"train\"].to_pandas()\ndf.head()\n</code></pre>"},{"location":"tutorial.html","title":"Loading and Working with ChemEx Datasets","text":"<p>This section demonstrates a basic usage scenario of one of the ChemEx datasets hosted on Hugging Face. The following code is fully reproducible in Google Colab or any Jupyter-based environment.</p> <p>The demo uses the cytox_NeurIPS_updated_data dataset, which contains cytotoxicity data for various nanomaterials. This example includes:</p> <ul> <li>Loading the dataset into a pandas DataFrame using the <code>datasets</code> library  </li> <li>Accessing the underlying Parquet file directly  </li> <li>Programmatically downloading and parsing the Croissant metadata description</li> </ul>"},{"location":"tutorial.html#1-installing-dependencies","title":"1. Installing Dependencies","text":"<pre><code>!pip install pandas datasets requests pyarrow\n</code></pre>"},{"location":"tutorial.html#2-loading-the-dataset-via-hugging-face-datasets","title":"2. Loading the Dataset via Hugging Face Datasets","text":"<p>To quickly access pre-processed datasets, we use the <code>datasets</code> library. It automatically fetches the <code>.parquet</code> file and converts it to a pandas DataFrame.</p> <pre><code>from datasets import load_dataset\n\n# Unique dataset identifier on Hugging Face\ndataset_id = \"ai-chem/Nanozymes\"\n\ndataset = load_dataset(dataset_id)\ndf = dataset[\"train\"].to_pandas()\n\ndf.head()\n</code></pre> <p>\ud83d\udccc Using <code>datasets</code> provides automatic integration with Croissant metadata.</p>"},{"location":"tutorial.html#3-alternative-load-the-raw-parquet-file","title":"3. Alternative: Load the Raw Parquet File","text":"<p>If you prefer direct control over file access \u2014 for example, loading a specific chunk \u2014 you can work directly with the raw <code>.parquet</code> file using pandas:</p> <pre><code>import pandas as pd\n\n# Direct link to Parquet file\nparquet_url = \"https://huggingface.co/datasets/ai-chem/Nanozymes/resolve/main/data/train-00000-of-00001.parquet\"\n\n# Loading with pandas and pyarrow\ndf = pd.read_parquet(parquet_url, engine=\"pyarrow\")\n\ndf.head()\n</code></pre> <p>\ud83d\udccc Ensure that the link points to the raw file using <code>/resolve/</code> instead of <code>/blob/</code>.</p>"},{"location":"tutorial.html#4-download-and-view-croissant-metadata","title":"4. Download and View Croissant Metadata","text":"<p>Each dataset in ChemEx includes a Croissant file \u2014 a machine-readable schema and metadata description in JSON-LD format. It is used for structural validation, typing, and metadata inspection.</p> <pre><code>import requests\n\n# Direct link to Croissant JSON file\nurl = \"https://huggingface.co/api/datasets/ai-chem/Nanozymes/croissant\"\n\n# Downloading\nresponse = requests.get(url)\n\n# Saving locally\nwith open(\"dataset.croissant.json\", \"wb\") as f:\n    f.write(response.content)\n</code></pre>"},{"location":"tutorial.html#5-load-and-inspect-metadata-structure","title":"5. Load and Inspect Metadata Structure","text":"<p>Open the Croissant file and display its contents:</p> <pre><code>import json\n\nwith open(\"dataset.croissant.json\", \"r\") as f:\n    croissant_data = json.load(f)\n\n# View in readable form\nprint(json.dumps(croissant_data, indent=2))\n</code></pre> <p>Optional: You can explore <code>recordSet</code>, <code>field</code>, and <code>dataType</code> to understand the schema.</p>"},{"location":"tutorial.html#summary","title":"Summary","text":"<p>This basic workflow demonstrates:</p> <ul> <li>Two approaches for accessing tabular data (via <code>datasets</code> and raw file streams)  </li> <li>Integration with open metadata and reproducibility standards (Croissant)  </li> <li>Compatibility between Hugging Face datasets, pandas, and JSON-based ecosystems</li> </ul>"},{"location":"tutorial.html#references","title":"References","text":"<ul> <li>Dataset page on Hugging Face </li> <li>Hugging Face Datasets documentation </li> <li>Croissant Specification (MLCommons)</li> </ul>"},{"location":"about/how_to_cite.html","title":"\u041a\u0430\u043a \u0446\u0438\u0442\u0438\u0440\u043e\u0432\u0430\u0442\u044c","text":""},{"location":"about/how_to_cite.html#_2","title":"\u0426\u0438\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0441\u0442\u0430\u0442\u044c\u0438","text":"<p>[\u041e\u0431\u0440\u0430\u0437\u0435\u0446 \u0446\u0438\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f]</p>"},{"location":"about/how_to_cite.html#_3","title":"\u0426\u0438\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u043e\u0432","text":"<p>[\u0418\u043d\u0441\u0442\u0440\u0443\u043a\u0446\u0438\u044f \u043f\u043e \u0446\u0438\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044e \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u044b\u0445 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u043e\u0432]</p>"},{"location":"about/license.html","title":"License","text":"LICENSE.md<pre><code>MIT License\n\nCopyright (c) 2025 Center for AI in Chemistry, ITMO University\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n</code></pre>"},{"location":"about/team.html","title":"\u041a\u043e\u043c\u0430\u043d\u0434\u0430 \u043f\u0440\u043e\u0435\u043a\u0442\u0430","text":""},{"location":"about/team.html#_2","title":"\u0420\u0443\u043a\u043e\u0432\u043e\u0434\u0438\u0442\u0435\u043b\u0438","text":"<p>[\u0418\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044f \u043e \u0440\u0443\u043a\u043e\u0432\u043e\u0434\u0438\u0442\u0435\u043b\u044f\u0445 \u043f\u0440\u043e\u0435\u043a\u0442\u0430]</p>"},{"location":"about/team.html#_3","title":"\u0418\u0441\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u0438","text":"<p>[\u0418\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044f \u043e\u0431 \u0438\u0441\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044f\u0445]</p>"},{"location":"about/team.html#_4","title":"\u0420\u0430\u0437\u0440\u0430\u0431\u043e\u0442\u0447\u0438\u043a\u0438","text":"<p>[\u0418\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044f \u043e \u0440\u0430\u0437\u0440\u0430\u0431\u043e\u0442\u0447\u0438\u043a\u0430\u0445]</p>"},{"location":"about/team.html#_5","title":"\u041a\u043e\u043d\u0442\u0430\u043a\u0442\u044b","text":"<p>[\u041a\u043e\u043d\u0442\u0430\u043a\u0442\u043d\u0430\u044f \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044f \u0434\u043b\u044f \u0441\u0432\u044f\u0437\u0438 \u0441 \u043a\u043e\u043c\u0430\u043d\u0434\u043e\u0439]</p>"},{"location":"datasets/dataset_1.html","title":"Cytotoxicity of nanoparticles in nor-","text":""},{"location":"datasets/dataset_1.html#mal-and-cancer-cell-lines","title":"mal and cancer cell lines","text":""},{"location":"datasets/dataset_1.html#original-data","title":"Original Data","text":"<p>Title: Cytotoxicity of nanoparticles in nor- mal and cancer cell lines Description: The dataset contains information on the toxicity of inorganic nanoparticles on various normal and cancer cell lines. Total number of records: 5535 Number of features (columns): 28 Data type: Mixed Application: Nanomaterials Automatic validation: Yes</p>"},{"location":"datasets/dataset_1.html#data-scheme","title":"Data Scheme","text":"<p>Below is a description of all the fields present in the dataset.</p>"},{"location":"datasets/dataset_1.html#cytotoxicity-dataset-column-descriptions","title":"Cytotoxicity Dataset \u2013 Column Descriptions","text":"Column Name Description material Composition of the nanoparticle/material tested (e.g., SiO\u2082, Ag). shape Physical shape of the particle (e.g., Sphere, Rod). coat/functional group Surface coating or functionalization (e.g., CTAB, PEG). synthesis method Synthesis method (e.g., Precipitation, Commercial etc.). surface charge Reported surface charge (e.g., Negative, Positive). size in medium (nm) Hydrodynamic size in biological medium (nm). zeta in medium (mV) Zeta potential in medium (mV; blank if not measured). no of cells (cells/well) Cell density per well in the assay. human/animal Origin of cells (A = Animal, H = Human). cell source Species/organism (e.g., Rat, Human). cell tissue Tissue origin of the cell line (e.g., Adrenal Gland, Lung). cell morphology Cell shape (e.g., Irregular, Epithelial). cell age Developmental stage of cells (e.g., Adult, Embryonic). time (hr) Exposure duration (hours). concentration Tested concentration of the material (unit-specific, e.g., \u00b5g/mL). test Cytotoxicity assay type (e.g., MTT, LDH). test indicator Reagent measured (e.g., TetrazoliumSalt for MTT). viability (%) Cell viability percentage relative to control. doi Digital Object Identifier (DOI) of the article. article_list Identifier for the article in the dataset. core size (nm) Primary particle size (nm). Hydrodynamic diameter (nm) Size in solution including coatings (nm). Zeta potential (mV) Surface charge in solution (mV). Cell type Specific cell line name (e.g., PC12, A549)."},{"location":"datasets/dataset_1.html#metadata","title":"Metadata","text":"Column Name Description journal_name Name of the publishing journal. publisher Publisher of the article. year Year of publication. title Title of the article. journal_is_oa Journal is Open Access (TRUE/FALSE). is_oa Article is Open Access (TRUE/FALSE; note typo \"FASLE\" in sample). oa_status Open Access status (e.g., hybrid, gold, closed). <p>Key Notes</p> <ul> <li><code>human/animal</code>: \"A\" for Animal, \"H\" for Human  </li> <li><code>viability (%)</code>: Values &gt;100% may indicate proliferation stimulation  </li> <li>Blanks: Missing values (e.g., zeta in medium) imply unreported data  </li> </ul>"},{"location":"datasets/dataset_1.html#text-description","title":"Text Description","text":"<p>The dataset contains experimental data on the effects of inorganic nanoparticles on human and animal cells. The main focus is on the assessment of cytotoxicity using standard tests (e.g., MTT) to understand how different nanoparticle characteristics (shape, size, charge, coating) affect cell survival.</p> <p>Each entry includes:</p> <ul> <li>Nanoparticle characteristics (material, shape, size, charge, etc.)</li> <li>Cell line information (source, tissue, morphology, etc.)</li> <li>Experimental conditions (exposure time, concentration, etc.)</li> <li>Results of cell survival tests</li> <li>Publication metadata (DOI, journal, year, etc.)</li> </ul> <p>The aim of the dataset is to contribute to the investigation of the patterns between nanoparticle parameters and their cytotoxic effects.</p>"},{"location":"datasets/dataset_1.html#validation-results","title":"Validation Results","text":"<p>Validation was performed manually using PDF versions of the publications. For each record, the following were checked:</p> <ul> <li>Data consistency with the original article  </li> <li>Correctness of numerical values and units of measurement  </li> <li>Presence and accuracy of fields such as \"cell tissue\", \"cell morphology\", \"Hydrodynamic diameter\", etc.</li> </ul>"},{"location":"datasets/dataset_1.html#benchmark-results","title":"Benchmark Results","text":"<p>Coming soon.</p>"},{"location":"datasets/dataset_11.html","title":"Magnetic Nanomaterials","text":""},{"location":"datasets/dataset_11.html#original-data","title":"Original Data","text":"<p>Title: Magnetic Nanomaterials Description: The dataset contains comprehensive information about magnetic nanoparticles, including core-shell structures and their magnetic properties. It combines three distinct datasets: two focusing on MRI and hyperthermia applications (from Pasha Kim), and one dedicated to exchange bias phenomena.</p> <p>Total number of records: 2579 Number of features (columns): 64 Data type: Mixed Application: Nanomaterials Automatic validation: Yes</p>"},{"location":"datasets/dataset_11.html#data-scheme","title":"Data Scheme","text":""},{"location":"datasets/dataset_11.html#dataset-structure","title":"Dataset Structure","text":"<p>The dataset is organized into several key categories:</p> <ol> <li>Compositional Data</li> <li>Core and shell materials</li> <li>Multiple shell layers (where applicable)</li> <li> <p>Normalized compositions</p> </li> <li> <p>Physical Characteristics</p> </li> <li>Size measurements from various techniques</li> <li>Morphological properties</li> <li> <p>Crystallographic information</p> </li> <li> <p>Magnetic Properties</p> </li> <li>SQUID measurements</li> <li>Exchange bias parameters</li> <li> <p>Magnetization data</p> </li> <li> <p>Application-specific Parameters</p> </li> <li>MRI-related properties</li> <li>Hyperthermia characteristics</li> </ol>"},{"location":"datasets/dataset_11.html#column-descriptions","title":"Column Descriptions","text":"Category Column Name Description Composition normalized_core Normalized core composition normalized_shell Normalized shell composition np_shell_2 Second shell composition (if present) np_shell_3 Third shell composition (if present) Size &amp; Structure np_hydro_size Hydrodynamic size (nm) xrd_scherrer_size Crystallite size from Scherrer equation emic_size Size from electron microscopy Magnetic Properties squid_h_min Minimum magnetic field in SQUID measurements squid_h_max Maximum magnetic field in SQUID measurements squid_sat_mag Saturation magnetization exchange_bias_shift Exchange bias field shift (Oe) Thermal Properties blocking_temperature Blocking temperature (K) curie_temperature Curie temperature (K) Characterization emic_exp_type Type of electron microscopy experiment xrd_crystallinity Crystallinity status space_group_core Space group of core material <p>[Note: This is a subset of columns. Full list contains 64 columns]</p>"},{"location":"datasets/dataset_11.html#metadata","title":"Metadata","text":"Column Name Description doi Digital Object Identifier journal_name Name of the publication journal publisher Publisher name year Publication year title Article title access Access type (0 - closed, 1 - open) verification_required Indicates if verification is needed verified_by Name of validator verification_date Date of verification <p>Key Notes</p> <ul> <li>Purpose: Extraction and structuring of magnetic properties data from nanoparticle research</li> <li>Key Features:   \u2022 Comprehensive magnetic characterization   \u2022 Multiple size measurement techniques   \u2022 Detailed crystallographic information   \u2022 Application-specific parameters (MRI, hyperthermia)</li> <li>Data Sources: Combines three distinct datasets with different focus areas</li> <li>Validation: Includes both automated and manual verification processes</li> </ul>"},{"location":"datasets/dataset_11.html#text-description","title":"Text Description","text":"<p>The Magnetic Nanomaterials Dataset is a comprehensive collection of data focusing on magnetic nanoparticles and their properties. It encompasses information from three distinct datasets, each contributing unique aspects of magnetic nanomaterial characterization:</p> <ul> <li>Core-shell structures and compositions</li> <li>Magnetic properties measured through various techniques</li> <li>Application-specific characteristics for medical applications</li> <li>Detailed structural and morphological information</li> </ul> <p>The dataset is particularly valuable for researchers working in: - Magnetic resonance imaging (MRI) - Magnetic hyperthermia - Exchange bias phenomena - Nanoparticle synthesis and characterization</p>"},{"location":"datasets/dataset_11.html#validation-results","title":"Validation Results","text":"<p>Validation process includes:</p> <ul> <li>Automated data extraction verification</li> <li>Manual cross-checking of numerical values</li> <li>Verification of unit conversions and standardization</li> <li>Structure and composition validation</li> <li>Metadata completeness checking</li> </ul> <p>Each entry undergoes verification with flags for: - Data accuracy (<code>has_mistake_in_data</code>) - Metadata accuracy (<code>has_mistake_in_metadata</code>) - Verification status tracking - Validator assignment and dating</p>"},{"location":"datasets/dataset_11.html#benchmark-results","title":"Benchmark Results","text":"<p>Coming soon.</p>"},{"location":"datasets/dataset_2.html","title":"SelTox \u2013 Toxicity of Inorganic Nanoparticles on Bacteria","text":""},{"location":"datasets/dataset_2.html#original-data","title":"Original Data","text":"<p>Title: SelTox dataset \u2013 Toxicity of inorganic nanoparticles in various normal and pathogenic bacterial strains Description: The dataset contains experimental information on the toxicity of inorganic nanoparticles tested against different bacterial strains, including both normal and multidrug-resistant (MDR) types. Total number of records: 3286 Number of features (columns): 30 Data type: Mixed Application: Nanomaterials Automatic validation: Yes</p>"},{"location":"datasets/dataset_2.html#data-scheme","title":"Data Scheme","text":""},{"location":"datasets/dataset_2.html#seltox-dataset-column-descriptions","title":"SelTox Dataset \u2013 Column Descriptions","text":"Column Name Description np Name of the nanoparticle (e.g., Ag, Au, ZnO). coating Surface coating/modification of the nanoparticle (if any: 1 = Yes, 0 = No). bacteria Bacterial strain tested (e.g., Enterococcus faecalis, Escherichia coli). mdr Indicates multidrug-resistant strain (1 = Yes, 0 = No). strain Specific strain identifier (if provided). np_synthesis Synthesis method (e.g., green_synthesis, chemical synthesis). method Assay type (e.g., MIC, ZOI). MIC_NP Minimum Inhibitory Concentration of the nanoparticle. concentration Concentration of nanoparticle used for ZOI measurement. zoi_np Zone of Inhibition (in mm) for the nanoparticle alone. np_size_min (nm) Minimum particle size (nm). np_size_max (nm) Maximum particle size (nm). np_size_avg (nm) Average particle size (nm). shape Particle morphology (e.g., spherical, rod-shaped). time_set Duration of the experiment (in hours). zeta_potential Zeta potential (mV); blank if not measured. reference Reference to study (URL or citation). doi Digital Object Identifier of the article. article_list Internal article identifier in dataset. Solvent for extract Solvent used in green synthesis (e.g., water, ethanol). Temperature for extract, C Temperature of extract preparation (\u00b0C). Duration preparing extract, min Duration of extract preparation (minutes). Precursor of NP Chemical precursor used (e.g., AgNO\u2083). Concentration of precursor (mM) Molar concentration of precursor. hydrodynamic diameter Hydrodynamic size in solution (if measured). pH during synthesis pH value during synthesis (if reported)."},{"location":"datasets/dataset_2.html#metadata","title":"Metadata","text":"Column Name Description journal_name Name of the publishing journal. publisher Publisher of the article. year Year of publication. title Title of the article. journal_is_oa Journal is Open Access (TRUE/FALSE). is_oa Article is Open Access (TRUE/FALSE). oa_status Open Access status (e.g., green, hybrid, closed). <p>Key Notes</p> <ul> <li><code>mdr</code>: 1 = Multidrug-resistant strain, 0 = Non-resistant  </li> <li>Units are embedded in column names (e.g., nm, mM, \u00b0C, mm)  </li> <li>Fields like <code>strain</code>, <code>zeta_potential</code>, <code>hydrodynamic diameter</code> may be blank if data is not reported  </li> <li><code>coating</code>: 0 = no coating, 1 = coating present  </li> <li>Validation and verification were conducted based on original articles in PDF format</li> </ul>"},{"location":"datasets/dataset_2.html#text-description","title":"Text Description","text":"<p>The SelTox dataset provides detailed experimental data on the antibacterial activity of inorganic nanoparticles against both normal and multidrug-resistant bacterial strains. It captures key physicochemical properties of nanoparticles (e.g., size, shape, synthesis method), assay conditions (e.g., MIC, ZOI), and biological targets (bacterial species and resistance status).</p> <p>Each record includes:</p> <ul> <li>Nanoparticle specifications (material, synthesis method, size, zeta potential)  </li> <li>Biological target information (bacterial species, MDR status)  </li> <li>Assay type and result (MIC, ZOI)  </li> <li>Conditions of synthesis (e.g., solvent, temperature, pH)  </li> <li>Metadata and publication references (DOI, journal, year, etc.)</li> </ul> <p>The goal of the dataset is to support research in nanotoxicology by enabling analysis of how nanoparticle characteristics correlate with antibacterial efficacy, particularly against drug-resistant strains.</p>"},{"location":"datasets/dataset_2.html#validation-results","title":"Validation Results","text":"<p>Validation was carried out manually using the original PDF articles available in the folder <code>seltox_article_list(only)</code>. Each record was cross-checked against the article to verify:</p> <ul> <li>Numerical accuracy (e.g., MIC values, nanoparticle sizes)  </li> <li>Correctness of units and synthesis parameters  </li> <li>Completeness of metadata (title, journal, DOI)</li> </ul> <p>The validation results are documented in the file: <code>Validation_SelTox_NeurIPS_updated_data</code></p> <p>Key columns in the validation table include:</p> <ul> <li><code>verification required</code> </li> <li><code>verified_by</code> </li> <li><code>verification_date</code> </li> <li><code>has_mistake_in_data</code> </li> <li><code>has_mistake_in_metadata</code> </li> <li><code>entry_status</code> (e.g., Requires correction)</li> </ul> <p>Example of issues flagged:</p> <ul> <li>Entry 2897 marked as <code>Requires correction</code> due to mistakes in data  </li> <li>All validation entries include timestamp and verifier name</li> </ul>"},{"location":"datasets/dataset_2.html#benchmark-results","title":"Benchmark Results","text":"<p>Coming soon.</p>"},{"location":"datasets/dataset_3.html","title":"Synergy \u2013 Toxicity of Drug, Nanoparticle, and Their Synergistic Effect on Bacterial Strains","text":""},{"location":"datasets/dataset_3.html#original-data","title":"Original Data","text":"<p>Title: Synergy dataset \u2013 Toxicity of drug, nanoparticle, and their synergistic effect on bacterial strains Description: The dataset contains experimental data on the antibacterial activity of individual drugs, nanoparticles (NPs), and their combinations against various bacterial strains. It includes measurements of inhibition zones, MIC values, viability, and calculated synergy metrics (e.g., FIC, fold increase). Total number of records: 3226 Number of features (columns): 34 Data type: Mixed Application: Nanomaterials Automatic validation: Yes  </p> <p>A complete data table can be found in the internal dataset file: <code>synergy_NeurIPS_updated_data</code></p>"},{"location":"datasets/dataset_3.html#data-scheme","title":"Data Scheme","text":""},{"location":"datasets/dataset_3.html#synergy-dataset-column-descriptions","title":"Synergy Dataset \u2013 Column Descriptions","text":"Column Name Description NP Name of the nanoparticle (e.g., Ag, Au, CuO). Bacteria Bacterial strain tested (e.g., Escherichia coli). ATCC(species) Strain identifier (e.g., MTCC 443, ATCC 25922). NP_Synthesis Synthesis method (e.g., chemical synthesis, green synthesis). Drug Name of the antibiotic/drug used in combination. Drug_dose Dosage/concentration of the drug. NP_concentration Required NP concentration to produce an antibacterial effect. NP_size_min(nm) Minimum size of nanoparticles (nm). NP_size_max_(nm) Maximum size of nanoparticles (nm). NP_size_avg_(nm) Average size of nanoparticles (nm). shape Morphology of the nanoparticles (e.g., spherical). method Assay type used (e.g., MIC, disc_diffusion, well_diffusion, etc.). ZOI_drug(mm)_or_Minimal_concentration Zone of inhibition (mm) or MIC for the drug alone. error_ZOI_drug(mm)_or_Minimal_concentration Error or standard deviation for drug-only measurement. ZOI_NP_or_MC_NP Zone of inhibition or MIC for the nanoparticle alone. error_ZOI_NP_or_MC_NP Error or standard deviation for NP-only measurement. ZOI_drug_NP_or_MIC_drug_NP Zone of inhibition or MIC for the drug + NP combination. error_ZOI_drug_NP_or_MIC_drug_NP Error or standard deviation for the combination. fold_increase_in_antibacterial_activity Enhancement in antibacterial activity due to synergy (fold change). Zeta_potential(mV) Surface charge of the nanoparticle (mV). MDR Multidrug-resistant strain (R = Resistant). FIC Fractional Inhibitory Concentration index. Effect Type of interaction (e.g., synergistic, additive). reference Citation or URL to the original publication. doi Digital Object Identifier (DOI) of the article. article_list Internal article identifier in the dataset. time_(hr) Duration of exposure (in hours). Coating_with_antimicrobial_peptide/polymers Surface modification with peptides or polymers (if used). combined_MIC Combined MIC of NP and peptide/polymer. peptide_MIC MIC of antimicrobial peptide alone. viability Bacterial viability (%) post-treatment. viability_error Error or standard deviation for viability."},{"location":"datasets/dataset_3.html#metadata","title":"Metadata","text":"Column Name Description journal_name Name of the publishing journal. publisher Publisher of the article. year Year of publication. title Title of the article. journal_is_oa Journal is Open Access (TRUE/FALSE). is_oa Article is Open Access (TRUE/FALSE). oa_status Open Access status (e.g., green, closed). <p>Key Notes</p> <ul> <li>Units: Embedded directly in column names (e.g., nm, mV, mm)  </li> <li>Missing values: Represented as blank cells (e.g., for Drug, peptide_MIC, etc.)  </li> <li>Synergy metrics: <code>FIC</code> and <code>fold_increase_in_antibacterial_activity</code> quantify interaction strength between drug and NP  </li> <li>MDR: Indicates resistance status (R = Resistant)  </li> <li>Coating: Captures presence of peptide/polymer coatings with antimicrobial properties  </li> </ul>"},{"location":"datasets/dataset_3.html#text-description","title":"Text Description","text":"<p>The Synergy dataset contains experimental data focused on evaluating the combined antibacterial effects of inorganic nanoparticles and conventional antibiotics. It includes tests performed on multiple bacterial strains, including standard and multidrug-resistant (MDR) variants.</p> <p>The dataset captures:</p> <ul> <li>Physicochemical properties of nanoparticles (size, shape, zeta potential, synthesis method)  </li> <li>Drug-specific details (name, dose, MIC, effect)  </li> <li>Antibacterial activity metrics:  </li> <li>Drug alone  </li> <li>Nanoparticle alone  </li> <li>Drug + NP combination  </li> <li>Synergy indicators (FIC, fold increase)  </li> <li>Bacterial viability after treatment  </li> <li>Metadata including publication source, year, and access status</li> </ul> <p>This dataset is intended to support research in nanomedicine and antimicrobial resistance, particularly in the design and evaluation of nanoparticle-drug combinations with synergistic effects.</p>"},{"location":"datasets/dataset_3.html#validation-results","title":"Validation Results","text":"<p>Validation was performed manually using the original PDF articles located in the folder: <code>synergy_article_list</code>.</p> <p>Each dataset entry was cross-checked for:</p> <ul> <li>Consistency with original source data  </li> <li>Accuracy of numerical values and units (e.g., MIC, ZOI)  </li> <li>Correctness of metadata (journal, DOI, title)</li> </ul> <p>Validation results are contained in: <code>Validation_synergy_NeurIPS_updated_data</code></p> <p>Key fields in the validation file include:</p> <ul> <li><code>verification required</code> </li> <li><code>verified_by</code> </li> <li><code>verification_date</code> </li> <li><code>has_mistake_in_data</code> </li> <li><code>has_mistake_in_metadata</code> </li> <li><code>entry_status</code></li> </ul>"},{"location":"datasets/dataset_3.html#benchmark-results","title":"Benchmark Results","text":"<p>Coming soon.</p>"},{"location":"datasets/dataset_4.html","title":"Nanozymes \u2013 Catalytic Properties of Nanozyme Materials","text":""},{"location":"datasets/dataset_4.html#original-data","title":"Original Data","text":"<p>Title: Nanozymes dataset \u2013 Comprehensive information about nanozyme materials and their catalytic activity Description: This dataset captures essential experimental information on nanozymes, including their chemical composition, structural and morphological properties, catalytic behavior, and reaction conditions. Data was manually extracted from scientific publications, with each row representing a unique experimental setup or measurement. The dataset supports the exploration of structure\u2013activity relationships and benchmarking of nanozyme performance under varying conditions. Total number of records: 1135 Number of features (columns): 27 Data type: Mixed Application: Nanomaterials Automatic validation: No</p>"},{"location":"datasets/dataset_4.html#data-scheme","title":"Data Scheme","text":""},{"location":"datasets/dataset_4.html#nanozymes-dataset-column-descriptions","title":"Nanozymes Dataset \u2013 Column Descriptions","text":"Column Name Description formula Chemical formula of the nanozyme (e.g., Fe\u2083O\u2084, CeO\u2082, Au, etc.) activity_type Type of catalytic activity (e.g., peroxidase-like, oxidase-like, catalase-like) syngony Crystal system (e.g., cubic, hexagonal, monoclinic) length(nm) Length of the nanoparticle (in nanometers) width(nm) Width of the nanoparticle (in nanometers) depth(nm) Depth/thickness of the nanoparticle (in nanometers) surface Surface modification or functionalization (e.g., PVP, PEG, doping) km_value Michaelis constant (Km) value km_unit Unit of Km (e.g., mM, \u00b5M) vmax_value Maximum reaction rate (Vmax) value vmax_unit Unit of Vmax (e.g., mM/s, \u00b5M/min) reaction_type Catalyzed reaction type (e.g., TMB + H\u2082O\u2082, ABTS, OPD + H\u2082O\u2082) c_min(mM) Minimum substrate concentration (mM) c_max(mM) Maximum substrate concentration (mM) c_const_value Constant concentration of a co-substrate (if used) c_const_unit Unit of the co-substrate concentration ccat_value Catalyst (nanozyme) concentration ccat_unit Unit of catalyst concentration (e.g., mg/mL, mM) ph pH at which the reaction was performed temperature Temperature in \u00b0C at which the reaction was performed"},{"location":"datasets/dataset_4.html#metadata","title":"Metadata","text":"Column Name Description doi Digital Object Identifier of the article title Title of the article journal Name of the publishing journal oa Open Access status of the article (TRUE/FALSE) year Year of publication <p>Key Notes</p> <ul> <li>Units: All concentration- and activity-related units are embedded directly in column names or represented in separate \"unit\" columns  </li> <li>Surface: If blank, indicates no surface modification or not reported  </li> <li>Missing values: Parameters not provided in an article are left blank in the dataset  </li> <li>Each row corresponds to a distinct experiment (not just a unique article)  </li> <li>Dataset is intended for benchmarking and structure\u2013activity analysis of nanozymes  </li> </ul>"},{"location":"datasets/dataset_4.html#text-description","title":"Text Description","text":"<p>The Nanozymes dataset aggregates detailed experimental measurements related to the catalytic properties of synthetic enzyme-mimicking nanoparticles (nanozymes). These materials mimic natural enzymes and are used in biosensing, environmental detection, and therapeutic applications.</p> <p>For each experiment, the dataset captures:</p> <ul> <li>Composition and structure: including chemical formula and crystal system (syngony)  </li> <li>Morphology: dimensions of the particles (length, width, depth)  </li> <li>Surface chemistry: coating or functional groups, if present  </li> <li>Catalytic performance: Michaelis constant (Km), maximum reaction rate (Vmax), type of catalytic reaction  </li> <li>Reaction conditions: substrate concentrations, catalyst concentration, pH, temperature  </li> </ul> <p>The dataset supports comprehensive benchmarking of nanozyme activity and deeper investigation into structure\u2013function relationships. It also facilitates machine learning and data-driven modeling in nanozyme design.</p>"},{"location":"datasets/dataset_4.html#validation-results","title":"Validation Results","text":"<p>Coming soon.</p>"},{"location":"datasets/dataset_4.html#benchmark-results","title":"Benchmark Results","text":"<p>Coming soon.</p>"},{"location":"datasets/dataset_5.html","title":"Benzimidazole Antibiotics \u2013 Chemical Structures and Antimicrobial Activity","text":""},{"location":"datasets/dataset_5.html#original-data","title":"Original Data","text":"<p>Title: Benzimidazole antibiotics \u2013 chemical structures and antimicrobial activity Description: This dataset contains information on the chemical structures of benzimidazole-based antibiotics in SMILES format, along with their antimicrobial activity measured as Minimum Inhibitory Concentration (MIC) values against different Staphylococcus aureus and Escherecia coli strains. In addition to structures and target values, the dataset includes metadata such as source articles, extraction pages, origin type (table, text, image). Total number of records: 1721 Number of extracted features (columns): 3 (main: SMILES and MIC), though the full table contains over 25 metadata columns Input data type: Mixed Domain: Small molecules / antibacterial compounds Automatic validation: Yes</p>"},{"location":"datasets/dataset_5.html#data-scheme","title":"Data Scheme","text":""},{"location":"datasets/dataset_5.html#column-descriptions","title":"Column Descriptions","text":"Column Name Description <code>smiles</code> Extracted chemical structure in isomeric SMILES format <code>doi</code> DOI of the article from which the data was extracted <code>title</code> Title of the article <code>publisher</code> Publisher <code>year</code> Year of publication <code>access</code> Access type (1 = open access, 0 = closed access) <code>compound_id</code> Compound identifier in the article <code>target_type</code> Type of target measurement (e.g., MIC or pMIC) <code>target_relation</code> Relation symbol (e.g., =, &gt;, &lt;) <code>target_value</code> Target value <code>target_units</code> Units of the target value (e.g., \u00b5g/mL) <code>bacteria</code> Bacterial species against which the compound was tested <code>bacteria_unified</code> Unified name of the bacterial species (e.g., Escherichia coli) <code>page_bacteria</code> Page number where the bacterium is mentioned in the article <code>origin_bacteria</code> Source of the bacterium mention (table, figure, text, image) <code>section_bacteria</code> Section of the article (if <code>origin_bacteria = text</code>) <code>subsection_bacteria</code> Subsection (if <code>origin_bacteria = text</code>) <code>page_target</code> Page number where the target value is provided <code>origin_target</code> Source of the target value (table, figure, text, image) <code>section_target</code> Section of the article (if <code>origin_target = text</code>) <code>subsection_target</code> Subsection (if <code>origin_target = text</code>) <code>page_scaffold</code> Page with the chemical scaffold or full molecule diagram <code>origin_scaffold</code> Origin of the scaffold image (table, figure, or unnumbered image) <code>page_residue</code> Page with substituent structures (if molecule is scaffold + residues) <code>origin_residue</code> Origin of the residue image (table, figure, or unnumbered image)"},{"location":"datasets/dataset_5.html#metadata","title":"Metadata","text":"Field Name Description <code>doi</code> DOI of the original article <code>title</code> Title of the publication <code>publisher</code> Publisher <code>year</code> Year of publication <code>access</code> Access type (0 = closed, 1 = open access) <p>Key Notes</p> <ul> <li>SMILES molecules may be presented:  </li> <li>As complete structures (use <code>scaffold</code> only)  </li> <li>As scaffold + substituents (use both <code>scaffold</code> and <code>residue</code> columns)  </li> <li>Target values (MIC/pMIC) are extracted with full context: value, units, source, and page  </li> <li>Bacterial names are provided in both raw and unified formats  </li> <li>Data origin types include:  </li> <li><code>table with number</code> (e.g., table 1)  </li> <li><code>figure with number</code> (e.g., scheme 1)  </li> <li><code>image</code> \u2013 unnumbered image inside the text  </li> <li><code>text</code> \u2013 if extracted directly from the article's text  </li> <li>Section/subsection fields are filled only when data is extracted from text or image  </li> </ul>"},{"location":"datasets/dataset_5.html#text-description","title":"Text Description","text":"<p>The goal of this dataset is to collect and structure chemical and biological data on benzimidazole-based antibiotics and their activity against bacterial pathogens. The primary target property is MIC (Minimum Inhibitory Concentration) expressed in \u00b5g/mL.</p> <p>Each record includes:</p> <ul> <li>A chemical structure in SMILES format  </li> <li>Information about the bacterial strain tested  </li> <li>The target value (type, relation, numeric value, unit)  </li> <li>Metadata about the source article (DOI, journal, year, publisher, access)  </li> <li>Detailed information on the source in the article (page, table, figure, text, or image)</li> </ul> <p>The dataset is intended for tasks such as scientific information extraction, QSAR modeling, structure\u2013activity analysis, and antibacterial research involving small molecules.</p>"},{"location":"datasets/dataset_5.html#validation-results","title":"Validation Results","text":"<p>Validation was performed manually using PDF versions of the articles located in the folder <code>benz_pdfs</code>. Each record was checked for:</p> <ul> <li>Accuracy of the SMILES structure vs. the diagram in the paper  </li> <li>Correctness of MIC values (units, relation sign, numeric value)  </li> <li>Match between bacteria and its mentioned source  </li> <li>Proper assignment of page numbers and origin types (table, text, image)</li> </ul> <p>The file includes:</p> <ul> <li>Whether verification is required (<code>verification required</code>)  </li> <li>Which records were verified  </li> <li>Status of verification  </li> </ul>"},{"location":"datasets/dataset_5.html#benchmark-results","title":"Benchmark Results","text":"<p>Coming soon.</p>"},{"location":"datasets/dataset_6.html","title":"Oxazolidinone Antibiotics","text":""},{"location":"datasets/dataset_6.html#original-data","title":"Original Data","text":"<p>Title: Oxazolidinone antibiotics</p> <p>Description: The dataset contains oxazolidinone antibiotics represented in SMILES format, along with their corresponding inhibitory concentrations (MIC or pMIC) against various bacterial strains. The data was extracted from scientific publications and includes detailed metadata about each measurement's origin, such as source (text, table, figure, or image) and exact location in the article (page, section, subsection).</p> <p>Total number of records: 3103 Number of features (columns): 34 Data type: Mixed (text, numeric, chemical structures) Application: Extraction of chemical structures and biological activity data for QSAR modeling and analysis of antibiotic effectiveness Automatic validation: Yes</p>"},{"location":"datasets/dataset_6.html#data-scheme","title":"Data Scheme","text":""},{"location":"datasets/dataset_6.html#dataset-column-descriptions","title":"Dataset \u2013 Column Descriptions","text":"Column Name Description smiles Extracted chemical structure in isomeric SMILES format doi DOI of the source article title Title of the article publisher Publisher of the article year Publication year access Access type (1 = open access, 0 = not open access) compound_id ID of the chemical compound in the article target_type Extracted target type (e.g., MIC, pMIC) target_relation Symbol preceding the target value (e.g., =, &gt;, &lt;) target_value Numerical value of the target measurement target_units Units of the target value (e.g., mol/l) bacteria Bacterial species related to the measurement bacteria_name_unified Unified name of the bacteria (normalized nomenclature) bacteria_info Additional information about the bacterial strain page_bacteria Page number where the bacterial name is found in the article origin_bacteria Source of the bacterial name (e.g., table, figure, text) section_bacteria Section of the article where the bacteria is mentioned (if origin is text) subsection_bacteria Subsection of the article (if origin is text) page_target Page number where the target value is found origin_target Source of the target value (e.g., table, figure, text) section_target Section of the article where the target is mentioned (if origin is text) subsection_target Subsection of the article (if origin is text) column_prop Not specified, possibly related to table column (empty in provided rows) line_prop Not specified, possibly related to table row (empty in provided rows) page_scaffold Page number of the scaffold or full structure in the article origin_scaffold Source of the scaffold (e.g., table, figure, image) section_scaffold Section of the article for scaffold (if origin is image) subsection_scaffold Subsection of the article for scaffold (if applicable) page_residue Page number of substituents for the scaffold origin_residue Source of the substituents (e.g., table, figure, image) section_residue Section of the article for substituents (if origin is image)"},{"location":"datasets/dataset_6.html#metadata","title":"Metadata","text":"Column Name Description verification_required Whether the record required manual verification verified_by Name of the person who verified the data verification_date Date when the verification was completed has_mistake_in_data Indicates if the chemical/biological data had a mistake has_mistake_in_matadata Indicates if the metadata had a mistake <p>Key Notes</p> <ul> <li>The dataset includes both full molecular structures and scaffold + substituent representations  </li> <li>Target values are reported as MIC or pMIC, with associated units and inequality relations  </li> <li>Metadata provides granular information about the source and location of the extracted data within scientific publications  </li> </ul>"},{"location":"datasets/dataset_6.html#text-description","title":"Text Description","text":"<p>Task: Extraction of chemical structures of antibiotics from the oxazolidinone class and their corresponding minimal inhibitory concentrations (MIC, target values) against various bacterial species.</p> <p>Extracted Entities: - SMILES molecules (column <code>smiles</code>, plus all columns containing <code>scaffold</code> and <code>residue</code>) \u2013 the molecule may be represented as a whole (metadata in <code>scaffold</code> columns) or as a scaffold with substituents (metadata in both <code>scaffold</code> and <code>residue</code> columns) - Target values (all columns with the word <code>target</code>) \u2013 MIC or pMIC values measured for specific bacterial strains - Bacteria (all columns with the word <code>bacteria</code>) \u2013 species for which the target value was measured  </p> <p>Metadata: - Article information: <code>doi</code>, <code>publisher</code>, <code>title</code>, <code>year</code>, <code>access</code> - Page: Page numbers in the article where data was extracted from - Origin: Source type \u2013 table (with number), figure (with number), text, image (unnumbered figure) - Section, Subsection: If the data is extracted from text or image, the section and subsection of the article are specified  </p>"},{"location":"datasets/dataset_6.html#validation-results","title":"Validation Results","text":"<p>Coming soon.</p>"},{"location":"datasets/dataset_6.html#benchmark-results","title":"Benchmark Results","text":"<p>Coming soon.</p>"},{"location":"datasets/dataset_7.html","title":"Chelate Complexes","text":""},{"location":"datasets/dataset_7.html#original-data","title":"Original Data","text":"<p>Title: Chelate Complexes Description: The dataset contains data on thermodynamic stability constants (lgK) of chelate complexes formed by gallium (Ga), gadolinium (Gd), technetium (Tc), lutetium (Lu), and a variety of chelating ligands. These complexes are studied as potential contrast agents in magnetic resonance imaging (MRI) and other diagnostic applications.</p> <ul> <li>Total number of records: 907  </li> <li>Number of features (columns): 21  </li> <li>Application: Small molecules</li> </ul>"},{"location":"datasets/dataset_7.html#data-scheme","title":"Data Scheme","text":""},{"location":"datasets/dataset_7.html#dataset-column-descriptions","title":"Dataset \u2013 Column Descriptions","text":"Column Name Description <code>pdf</code> PDF filename in the folder (for reference) <code>doi</code> DOI of the article <code>doi_source</code> Source article DOI if cited in a review paper; otherwise same as DOI <code>supplementary</code> 0 - data from main article; 1 - data from supplementary materials <code>title</code> Article title <code>publisher</code> Publishing organization <code>year</code> Publication year <code>access</code> 1 - open access; 0 - closed access <code>compound_id</code> Chemical structure ID in the article <code>compound_name</code> Chemical structure name in the article <code>smiles</code> Extracted chemical structure of ligand(s) in canonical SMILES format (without stereochemistry) <code>smiles_type</code> ligand - single ligand; environment - complex with removed metal (effectively the environment) <code>metal</code> Metal that forms complex with the corresponding ligand <code>target</code> Value of the target property (lgK) <code>page_smiles</code> Page number where ligand figure/SMILES is located <code>origin_smiles</code> Source of SMILES extraction. Options: figure N, table N, scheme N <code>page_metal</code> Page number where metal name is mentioned <code>origin_metal</code> Source of metal name extraction. Selection logic: title (if article focuses on one metal), table N caption (if multiple metals with stability constants table), subtitle N (in other cases) <code>page_target</code> Page number where target value is located <code>origin_target</code> Source of target value extraction. Options: table N, section N (text)"},{"location":"datasets/dataset_7.html#key-notes","title":"Key Notes","text":"<p>Objective: To collect and standardize thermodynamic data for metal\u2013ligand complexes from the literature, with a focus on compounds likely to be used as contrast agents in medical applications.</p> <p>Extracted entities include: - <code>compound_id</code> \u2013 compound's identifier - <code>compound_name</code> \u2013 compound's abbreviated name - <code>smiles</code> \u2013 ligand structure in canonical SMILES notation - <code>metal</code> \u2013 metal forming the complex - <code>target</code> \u2013 thermodynamic stability constant (lgK)</p> <p>Notes: - All structures are converted into canonical SMILES format using RDKit. - Stereochemistry is intentionally stripped to ensure standardization. - The dataset includes only structures and values that were directly available in the source documents and satisfied certain extraction criteria.</p>"},{"location":"datasets/dataset_7.html#text-description","title":"Text Description","text":"<p>This dataset provides curated measurements of the thermodynamic stability constants (lgK) for metal\u2013ligand complexes, extracted from scientific publications. These stability constants reflect the strength of binding between metal (such as Gd, Ga, Tc, Lu) and chelating organic ligands.</p> <p>Each record represents a distinct complex and includes: - an extracted ligand structure (<code>smiles</code>) - the central metal ion involved (<code>metal</code>) - the thermodynamic constant (<code>target</code>, as lgK) - bibliographic metadata and direct page/section references</p> <p>This dataset can be used to facilitate the study of metal\u2013ligand binding behavior and to serve as a benchmark for information extraction tools in chemical and biomedical domains.</p>"},{"location":"datasets/dataset_7.html#validation-results","title":"Validation Results","text":"<p>\u2013</p>"},{"location":"datasets/dataset_7.html#benchmark-results","title":"Benchmark Results","text":"<p>Coming soon.</p>"},{"location":"datasets/dataset_8.html","title":"Eye Drops","text":""},{"location":"datasets/dataset_8.html#original-data","title":"Original Data","text":"<p>Title: Eye Drops Description: The dataset contains data on the corneal permeability of small molecules represented in SMILES format. The compounds are primarily pharmaceutical substances, and the dataset was compiled to support the development of predictive models for corneal permeability \u2013 a key factor in ophthalmic drug delivery.</p> <p>Total number of records: 163 Number of features (columns): 2 (main extracted features: permeability and logP) Data type: Tables Application: Small molecules Automatic validation: Yes</p>"},{"location":"datasets/dataset_8.html#data-scheme","title":"Data Scheme","text":""},{"location":"datasets/dataset_8.html#dataset-column-descriptions","title":"Dataset \u2013 Column Descriptions","text":"Column Name Description smiles SMILES of the compound. Not directly extracted from the article; manually drawn and curated. name Name of the compound (e.g., 4-Chlorobenzensulfonamide, Acebutolol). perm (cm/s) Corneal permeability. Extracted directly when available, or calculated from logP. logP Logarithm of permeability. Extracted when available, or calculated from permeability. doi DOI of the article (if available). PMID PubMed ID of the article. title Title of the article. publisher Publisher of the article. year Year of publication. access 1 \u2013 open access; 0 \u2013 closed access. page Page number where the data was located. origin Source of the data in the article (e.g., table 3). verification_required TRUE/FALSE \u2013 whether the entry required manual verification. verified_by Name of the person who verified the entry. verification_date Date of verification. has_mistake_in_data TRUE/FALSE \u2013 whether a mistake was found in the data. has_mistake_in_metadata TRUE/FALSE \u2013 whether a mistake was found in the metadata. entry_status Status of the entry (e.g., Verified)."},{"location":"datasets/dataset_8.html#metadata","title":"Metadata","text":"Column Name Description doi DOI of the article (if available) PMID PubMed ID of the article title Title of the publication publisher Name of the publisher year Year of publication access Open access (1) or not (0) page Page number where the data is located origin Source location within the article (e.g., table 3) <p>Key Notes</p> <ul> <li>Objective: Extraction and structuring of corneal permeability data for small molecules used in ophthalmology  </li> <li>Extracted entities:   \u2022 SMILES of compound   \u2022 Corneal permeability (<code>perm (cm/s)</code>)   \u2022 Logarithm of permeability (<code>logP</code>)  </li> <li>SMILES were not directly extracted from the articles \u2013 they were drawn manually based on compound names and additional table information  </li> <li>Additional metadata is included to support traceability (e.g., PMID, DOI, title, publisher, year)  </li> <li>Validation includes manual verification and error flagging for both data and metadata  </li> </ul>"},{"location":"datasets/dataset_8.html#text-description","title":"Text Description","text":"<p>The Eye Drops dataset compiles structured data on the corneal permeability of pharmaceutical compounds, which is a critical property for evaluating the effectiveness of topical ophthalmic drugs. The dataset includes 163 entries, each representing a distinct compound.</p> <p>For each entry, the following are recorded:</p> <ul> <li>SMILES structure  </li> <li>Compound name  </li> <li>Permeability (in cm/s)  </li> <li>logP value  </li> </ul> <p>SMILES structures were obtained manually based on compound names presented in the articles, especially when names were incomplete or represented as derivatives. Where only logP or permeability values were available, the corresponding missing value was calculated.</p> <p>Comprehensive metadata is provided for each entry, including bibliographic details (e.g., title, publisher, year, access type, page, and origin of data). Each entry has been manually reviewed and verified where necessary, with flags indicating any errors found in content or metadata.</p>"},{"location":"datasets/dataset_8.html#validation-results","title":"Validation Results","text":"<p>Validation process description:</p> <ul> <li>Manual drawing and curation of SMILES structures based on compound names and supplementary information in the articles  </li> <li>Cross-checking of permeability/logP values and recalculation where needed  </li> <li>Manual verification of each entry by a designated validator (Xenia), including:   \u2022 Verification of chemical structure accuracy   \u2022 Accuracy of permeability and logP values   \u2022 Verification of bibliographic metadata  </li> <li>Error flags (<code>has_mistake_in_data</code>, <code>has_mistake_in_metadata</code>) used to track issues  </li> <li>Verification status (<code>Verified</code>) and date recorded  </li> </ul>"},{"location":"datasets/dataset_8.html#benchmark-results","title":"Benchmark Results","text":"<p>Coming soon.</p>"},{"location":"datasets/dataset_9.html","title":"Improved Photostability due to Multi-Component Crystals Formation","text":""},{"location":"datasets/dataset_9.html#original-data","title":"Original Data","text":"<p>Title: Improved Photostability due to Multi-Component Crystals Formation Description: The dataset contains information on photostable drug molecules and their multi-component crystalline forms (cocrystals or salts). For each entry, data is extracted on the drug, coformer, their molecular structures in SMILES format, the ratio in the crystal, and the change in photostability relative to the original drug.</p> <p>Total number of records: 70 Number of features (columns): 7 (main extracted features) Data type: Mixed Application: Small molecules Automatic validation: Yes</p>"},{"location":"datasets/dataset_9.html#data-scheme","title":"Data Scheme","text":""},{"location":"datasets/dataset_9.html#dataset-column-descriptions","title":"Dataset \u2013 Column Descriptions","text":"Column Name Description name cocrystal Name of multi-component crystal in the article ratio cocrystal Component ratio forming the multi-component crystal name drug Name of the drug compound SMILES drug Canonical SMILES of the drug molecule name coformer Name of the coformer used in the crystal SMILES coformer Canonical SMILES of the coformer molecule photostability change Description of change in photostability (e.g., increases, decreases, does not change)"},{"location":"datasets/dataset_9.html#metadata-article-and-source-information","title":"Metadata \u2013 Article and Source Information","text":"Column Name Description pdf PDF file name doi DOI of the publication supplementary 0 \u2013 from main article; 1 \u2013 from supplementary materials authors List of authors title Full title of the article journal Journal name year Year of publication open access 1 \u2013 open access; 0 \u2013 closed access page Page or article ID number *_type file Source of the data (e.g., manuscript, text, figure, scheme, table) *_origin Location in the article (e.g., figure 1, table 2, text) *_page Page number where the information is found <p>Key Notes</p> <ul> <li>Objective: Extraction of chemical structures of drugs and coformers forming a multi-component crystal (cocrystal or salt), and the corresponding change in photostability of the solid form compared to the original drug  </li> <li>Extracted entities:   \u2022 Name of cocrystal (<code>name cocrystal</code>)   \u2022 Component ratio (<code>ratio cocrystal</code>)   \u2022 Drug name and SMILES (<code>name drug</code>, <code>SMILES drug</code>)   \u2022 Coformer name and SMILES (<code>name coformer</code>, <code>SMILES coformer</code>)   \u2022 Photostability change (<code>photostability change</code>)  </li> <li>Metadata includes:   \u2022 Bibliographic information (DOI, authors, journal, title, year, open access)   \u2022 Source type and page (manuscript, figure, table, etc.)   \u2022 Supplementary material indicator  </li> <li>Not included when:   \u2022 Crystalline structure (Refcode) is not specified   \u2022 There are errors in data transferred from figures   \u2022 Photodegradation mechanism of the original molecule is not described  </li> </ul>"},{"location":"datasets/dataset_9.html#text-description","title":"Text Description","text":"<p>This dataset focuses on the photostability of pharmaceutical molecules and the effect of forming multi-component crystals (cocrystals or salts) with coformers. Photostability is a critical property in drug formulation, as exposure to light can degrade therapeutic compounds.</p> <p>The dataset captures the relationship between the crystal form and the photostability of the drug by documenting:</p> <ul> <li>The identity and ratio of components in the crystal  </li> <li>Molecular structures of the drug and coformer (in SMILES format)  </li> <li>Reported change in photostability compared to the original drug  </li> </ul> <p>Information was extracted from peer-reviewed publications and supplementary materials. SMILES structures were taken from figures or manually interpreted based on names and structures. Each record includes a detailed citation trail (DOI, journal, authors, etc.) and data source within the article (e.g., table, figure, or text).</p> <p>Manual validation flags indicate entries needing correction or further review.</p>"},{"location":"datasets/dataset_9.html#validation-results","title":"Validation Results","text":"<p>Validation process description:</p> <ul> <li>Manual extraction of drug/coformer names and their SMILES from figures and text  </li> <li>Recording the component ratio and photostability change as described in the article  </li> <li>Cross-checking SMILES for accuracy and consistency  </li> <li>Flagging issues such as:   \u2022 Errors in SMILES (drug or coformer)   \u2022 Missing or inaccurate origin details   \u2022 Unclear photostability interpretation  </li> </ul> <p>Validation metadata includes:</p> <ul> <li><code>verification_required</code>: Whether manual review was needed  </li> <li><code>verified_by</code>: Validator's name  </li> <li><code>verification_date</code>: Date of review  </li> <li><code>has_mistake_in_data</code>: Whether data errors were found  </li> <li><code>has_mistake_in_metadata</code>: Whether metadata errors were found  </li> <li><code>entry_status</code>: Final status (e.g., Verified, Requires correction)  </li> <li><code>comment</code>: Notes on specific issues (e.g., incorrect SMILES)  </li> </ul>"},{"location":"datasets/dataset_9.html#benchmark-results","title":"Benchmark Results","text":"<p>Coming soon.</p>"},{"location":"methods/approach.html","title":"Methodological Approach","text":""},{"location":"methods/approach.html#overview","title":"Overview","text":"<p>This section outlines the methodological framework of the ChemEx project, which forms the foundation for creating high-quality, multimodal chemical datasets. It presents the core pipeline stages \u2014 from extraction to benchmarking \u2014 and highlights the guiding principles behind the design of the data processing workflows.</p>"},{"location":"methods/approach.html#general-pipeline","title":"General Pipeline","text":"<pre><code>graph TD\n    A[Scientific Publications] --&gt; B[Automated Extraction]\n    B --&gt; C[Preprocessing &amp; Structuring]\n    C --&gt; D[Expert Validation]\n    D --&gt; E[Dataset Assembly]\n    E --&gt; F[Benchmarking &amp; Evaluation]</code></pre> <p>Core data processing pipeline used in ChemEx</p>"},{"location":"methods/approach.html#methodological-principles","title":"Methodological Principles","text":"<p>Core Design Principles</p> <ul> <li>Domain coverage: datasets span multiple chemical areas (e.g., nanomaterials, ionic liquids, small molecules)</li> <li>Multimodal input: structured extraction from text, tables, and figures</li> <li>Hybrid automation: combination of LLM-based extraction with expert review</li> <li>Reproducibility: public schemas, transparent metadata, and documentation</li> <li>Rigorous validation: use of standardized benchmarks to assess model performance</li> </ul>"},{"location":"methods/approach.html#methodological-components","title":"Methodological Components","text":""},{"location":"methods/approach.html#1-data-extraction","title":"1. Data Extraction","text":"<p>Information is automatically extracted from PDFs of scientific papers using a combination of:</p> <ul> <li>Large Language Models (LLMs) for text interpretation and extraction</li> <li>OCR and structure recognition tools such as MolScribe and DECIMER for parsing chemical structures and figures</li> <li>Domain-specific NLP models like ChemBERTa for named entity recognition and relation extraction</li> </ul> <p>Learn more about data extraction</p>"},{"location":"methods/approach.html#2-data-validation","title":"2. Data Validation","text":"<p>To ensure data accuracy, extracted outputs are systematically reviewed by domain experts. This includes:</p> <ul> <li>Manual cross-checking and correction of extracted data  </li> <li>Consistency validation against chemical knowledge and known properties  </li> <li>Error analysis of model-generated outputs (e.g., hallucinations or misparsed values)</li> </ul> <p>Learn more about data validation</p>"},{"location":"methods/approach.html#3-benchmarking-and-evaluation","title":"3. Benchmarking and Evaluation","text":"<p>Performance of automated methods is assessed via structured benchmarks using manually curated datasets. Evaluation includes:</p> <ul> <li>Standard metrics (e.g., precision, recall, F1 score, exact match)  </li> <li>Visualization tools (e.g., radar charts, confusion matrices) for intuitive comparison  </li> <li>Detailed error breakdown to guide future model improvements</li> </ul> <p>Learn more about benchmarking</p>"},{"location":"methods/approach.html#relationship-to-datasets","title":"Relationship to Datasets","text":"<p>Applying the Pipeline to CDEB Datasets</p> <ul> <li>All datasets are processed through the unified ChemEx pipeline  </li> <li>Method parameters are tuned to the specifics of each dataset (e.g., image-heavy nanomaterials vs. text-based small molecules)  </li> <li>Validation and benchmarking outcomes are documented and released with the datasets</li> </ul> <p>\ud83d\udcc1 Explore the Datasets Description section to see how methodology shapes each dataset.</p>"},{"location":"methods/approach.html#conclusion","title":"Conclusion","text":"<p>The ChemEx methodology provides a robust and scalable framework for producing high-quality chemical datasets. It bridges cutting-edge AI tools with expert human oversight, enabling reliable information extraction across the complex landscape of chemical literature.</p>"},{"location":"methods/benchmarking.html","title":"Benchmarking","text":""},{"location":"methods/benchmarking.html#general-concept","title":"General Concept","text":"<p>Benchmarking in the ChemExtra project is aimed at evaluating the performance of automated systems for extracting chemical information from scientific literature.</p> <p>The evaluation compares different approaches and types of models, including:</p> <ul> <li>large language models (LLMs),</li> <li>multimodal systems,</li> <li>multi-agent systems.</li> </ul> <p>The goal is to identify the strengths and weaknesses of existing tools and methodologies, and to obtain practical insights into the capabilities of current models for chemical data extraction.</p>"},{"location":"methods/benchmarking.html#methodology","title":"Methodology","text":"<p>The benchmarking covers a wide range of chemical domains, including nanomaterials and small molecules. Experiments were conducted in two key evaluation settings:</p>"},{"location":"methods/benchmarking.html#mono-agent-single-models","title":"Mono-agent (single models)","text":"<p>Individual language models such as GPT-4o and LLaMA-4 were evaluated independently. The models processed input in PDF and JPEG formats and were tasked with extracting chemical information, including:</p> <ul> <li>chemical entity recognition,</li> <li>relation and property extraction,</li> <li>construction of property\u2013value pairs.</li> </ul>"},{"location":"methods/benchmarking.html#multi-agent-agent-based-workflows","title":"Multi-agent (agent-based workflows)","text":"<p>For more complex tasks, the NanoMINER system was used, involving multiple specialized agents. Specifically:</p> <ul> <li>a YOLO-based agent was used for extracting information from images,</li> <li>a GPT-4o-based agent was used for text-based entity recognition.</li> </ul> <p>This approach is designed for handling multimodal documents that include textual descriptions, tables, and figures.</p>"},{"location":"methods/benchmarking.html#benchmarking-tasks","title":"Benchmarking Tasks","text":"<p>The evaluation covers the following types of extraction tasks:</p> <ul> <li>Entity Recognition \u2014 extracting chemical entities such as compounds, materials, properties;</li> <li>Property\u2013Value Extraction \u2014 extracting property\u2013value pairs from scientific text;</li> <li>Figure\u2013Text Linking \u2014 linking visual elements (figures) with their corresponding textual descriptions.</li> </ul>"},{"location":"methods/benchmarking.html#evaluation-metrics","title":"Evaluation Metrics","text":"<p>To measure the quality of extracted information, the following metrics were used:</p> <ul> <li>Precision \u2014 the proportion of correctly extracted elements out of all predicted elements.</li> <li>Recall \u2014 the proportion of correctly extracted elements out of all relevant (ground truth) elements.</li> <li>F1 Score \u2014 the harmonic mean of precision and recall.</li> <li>Error Rate \u2014 the number of errors in extraction; lower values indicate better performance.</li> <li>Task-Specific Metrics \u2014 additional metrics used in multimodal tasks, such as the accuracy of text\u2013figure linking.</li> </ul> <p>These metrics allow for a comprehensive assessment of the reliability of LLM-based and agent-based systems when working with complex chemical documents.</p>"},{"location":"methods/benchmarking.html#experiment-results","title":"Experiment Results","text":"<p>The results showed that:</p> <ul> <li> <p>GPT-4o and LLaMA-4 demonstrated high precision and recall in text-based tasks, especially for chemical entity recognition.</p> </li> <li> <p>However, these models showed reduced performance when processing multimodal data, such as linking figures to their textual context.</p> </li> <li> <p>The NanoMINER system, which follows a multi-agent architecture, performed better in multimodal tasks, particularly in linking figures to corresponding textual segments and extracting data from figure content.</p> </li> </ul>"},{"location":"methods/benchmarking.html#code-example-column-wise-metric-calculation","title":"Code Example: Column-wise Metric Calculation","text":"<p>Below is the code used to compute precision, recall, and F1 score for each column individually:</p> <pre><code>def calc_metrics(\n    df_true: pd.DataFrame,\n    df_pred: pd.DataFrame\n) -&gt; pd.DataFrame:\n\n    metrics = {}\n    from copy import deepcopy\n    for col in df_true.columns:\n        if col == \"pdf\": continue\n        true_values = list(df_true[col].astype(str).values)\n        pred_values = list(df_pred[col].astype(str).values)\n\n        tv = deepcopy(true_values)\n        pv = deepcopy(pred_values)\n        tp = 0\n\n        for val in tv:\n            if val in pv:\n                pv.pop(pv.index(val))\n                tp += 1\n\n        fp = 0\n        tv = deepcopy(true_values)\n        pv = deepcopy(pred_values)\n\n        for val in pv:\n            if val in tv:\n                tv.pop(tv.index(val))\n            else:\n                fp += 1\n\n        fn = 0\n        tv = deepcopy(true_values)\n        pv = deepcopy(pred_values)\n\n        for val in tv:\n            if val in pv:\n                pv.pop(pv.index(val))\n            else:\n                fn += 1\n\n        precision = tp / (tp + fp) if (tp + fp) &gt; 0 else 0.0\n        recall = tp / (tp + fn) if (tp + fn) &gt; 0 else 0.0\n        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) &gt; 0 else 0.0\n\n        metrics[col] = {\n            \"tp\": tp,\n            \"fp\": fp,\n            \"fn\": fn,\n            \"precision\": precision,\n            \"recall\": recall,\n            \"f1\": f1\n        }\n    return pd.DataFrame(metrics).T\n</code></pre>"},{"location":"methods/data_extraction.html","title":"Data extraction","text":""},{"location":"methods/data_extraction.html#methodology","title":"Methodology","text":"<p>The data extraction methodology focuses on the automated extraction of chemical information from scientific literature, utilizing advanced natural language processing (NLP) and machine learning (ML) techniques. The ChemExtra benchmark leverages multimodal datasets, including textual data, tables, and figures, for evaluating automated information extraction systems. The methodology incorporates a comprehensive data curation process, involving manual annotation by domain experts and iterative validation to ensure high accuracy and consistency across various chemical domains such as nanomaterials and small molecules.</p>"},{"location":"methods/data_extraction.html#tools","title":"Tools","text":"<p>To facilitate data extraction, state-of-the-art tools and models are employed. These include large language models (LLMs) like GPT-4o and LLaMA-4, which are capable of processing multimodal data (text and images). Additionally, the NanoMINER multi-agent system is utilized for extracting structured data from research articles, combining vision-based extraction methods with NLP capabilities. The system integrates YOLO for visual data extraction and GPT-4o for linking textual and visual information, ensuring end-to-end processing with minimal manual intervention.</p>"},{"location":"methods/data_extraction.html#extraction-process","title":"Extraction Process","text":"<p>The data extraction process follows a systematic approach:</p> <ol> <li> <p>Data Collection: Scientific articles are gathered from a broad corpus of peer-reviewed literature, focusing on chemical publications that include structured tables, unstructured text, and visually grounded references such as figures and plots.</p> </li> <li> <p>Preprocessing: The raw data is preprocessed to ensure machine-readability. For example, chemical names are standardized into SMILES notation, and figures are manually redrawn to extract chemical structures.</p> </li> <li> <p>Annotation: Domain experts annotate various chemical entities, properties, and synthesis protocols, ensuring consistency in the extracted data across different formats.</p> </li> <li> <p>Model Application: LLMs like GPT-4o are tasked with extracting key chemical features from both text and images. These models are trained and evaluated using curated datasets to ensure accurate extraction of information such as chemical names, properties, and relationships.</p> </li> <li> <p>Validation and Quality Control: A multi-stage validation system ensures the quality and reliability of the extracted data. A subset of annotated samples undergoes cross-checking by independent annotators, and iterative cycles of validation and correction are performed until the error rates converge to an acceptable threshold.</p> </li> </ol>"},{"location":"methods/data_extraction.html#results","title":"Results","text":"<p>The results demonstrate the effectiveness of the methodology in extracting chemical data from complex scientific literature. The use of multimodal models, particularly those capable of processing both text and images, significantly improves the accuracy of data extraction. The ChemExtra benchmark, comprising 11 curated datasets across diverse chemical domains, offers a robust foundation for evaluating and training models in the field of chemical information extraction. Despite the complexity of the task, current models, including LLMs and multi-agent systems, show promising results in automating the extraction process, though challenges remain in terms of performance across different types of data (text vs. images).</p>"},{"location":"methods/data_validation.html","title":"Data validation","text":""},{"location":"methods/data_validation.html#validity-criteria","title":"Validity Criteria","text":"<p>The data validation process is critical to ensuring the accuracy and consistency of the annotations within the ChemExtra dataset. The validity criteria focus on several key aspects:  </p> <ol> <li> <p>Entity Identification: Ensuring that chemical entities such as compounds, properties, and reaction conditions are correctly identified in the text and figures. </p> </li> <li> <p>Property-Value Pairing: Verifying that property-value pairs (e.g., molecular weight, reaction yields) are correctly associated with their respective entities.  </p> </li> <li> <p>Figure-Text Linking: Ensuring that relationships between figures (e.g., chemical structures) and the corresponding textual descriptions are accurate and consistent.  </p> </li> <li> <p>Data Consistency: Cross-checking annotations across multiple sources to ensure that the data is consistent across various articles and that no contradictory information is present.  </p> </li> </ol>"},{"location":"methods/data_validation.html#validation-process","title":"Validation Process","text":"<p>The validation process is a multi-stage, iterative procedure designed to ensure the reliability of the data extracted from the scientific literature:</p> <ol> <li> <p>Stratified Sampling: A minimum of 20% of the annotated instances from each article are selected for validation. This ensures that a representative sample of the data is checked for consistency and accuracy.</p> </li> <li> <p>Independent Cross-Checking: Annotated samples are reviewed by independent annotators who verify whether the annotations (e.g., entity spans, property-value pairings) are correct. Errors or inconsistencies are flagged for review.</p> </li> <li> <p>Error Logging: Errors are logged with binary flags to indicate whether the annotation is correct or incorrect, and the type of error (e.g., repetitive or single error) is identified.</p> </li> <li> <p>Iterative Correction: Following each validation cycle, errors are corrected, and additional samples are selected for review. The process continues until error rates converge to an acceptable threshold, ensuring high-quality annotations across the dataset.</p> </li> </ol>"},{"location":"methods/data_validation.html#error-handling","title":"Error Handling","text":"<p>When errors are identified, they are handled through a targeted correction process:</p> <ol> <li> <p>False Positives: Incorrect annotations flagged during validation (false positives) are reviewed and corrected. These corrections are added to the next validation cycle to ensure the data quality improves over time.</p> </li> <li> <p>Repetitive Errors: In cases where repetitive errors are found, all instances from the corresponding article are reviewed and corrected.</p> </li> <li> <p>Continuous Improvement: The iterative error correction loop ensures that each new validation cycle progressively improves the overall quality of the data, reducing error rates and enhancing the consistency of the annotations.</p> </li> </ol>"},{"location":"methods/data_validation.html#validation-results","title":"Validation Results","text":"<p>The validation process has led to high accuracy and consistency across the ChemExtra datasets. The multi-stage validation system, combined with the expert-driven annotation and error correction cycles, has resulted in minimal errors across all datasets. For example, in the Cytotox and Seltox datasets, the error rates were reduced to near zero after several cycles of validation and correction. The iterative approach has proven effective in ensuring that the datasets are of the highest quality, with both chemical entity identification and figure-text linkage achieving high precision and recall rates.</p>"},{"location":"overview/datasets_description.html","title":"Dataset Overview","text":""},{"location":"overview/datasets_description.html#introduction","title":"Introduction","text":"<p>This section summarizes the datasets included in the Chemical Data Extraction Benchmark (CDEB) \u2014 a curated collection designed to support training and evaluation of models for multimodal information extraction from chemistry publications.</p> <p>The datasets span a wide range of chemical subdomains and include annotations from text, tables, and visual content such as plots and chemical diagrams.</p> <p>Data Quality</p> <p>All datasets were manually annotated and rigorously cross-validated by chemistry experts to ensure high accuracy and consistency.</p>"},{"location":"overview/datasets_description.html#data-types-and-sources","title":"Data Types and Sources","text":"<p>The datasets were constructed from full-text PDFs of peer-reviewed articles, combining both automated extraction and manual correction. Each dataset may include:</p> <ul> <li>Experimental values (e.g., MIC, logP, lgK, catalytic constants)  </li> <li>Chemical identifiers and structures (e.g., SMILES, compound names)  </li> <li>Tabular and visual content (figures, plots, spectra, diagrams)  </li> <li>Source metadata (DOI, title, authors, journal, year, accessibility)</li> </ul> <p>Data originated from:</p> <ul> <li>Main article bodies  </li> <li>Supplementary materials  </li> <li>Structured tables and unstructured figures  </li> <li>OCR and model-assisted extraction workflows</li> </ul> <p>Multimodal Composition</p> <p>CDEB datasets contain text, table, and figure-based data, enabling the evaluation of models that process diverse input formats.</p>"},{"location":"overview/datasets_description.html#dataset-structure-and-organization","title":"Dataset Structure and Organization","text":"<p>Each dataset is provided in a structured tabular format (CSV or Parquet), and is accompanied by:</p> <ul> <li>Full provenance metadata  </li> <li>A detailed schema describing fields and units  </li> <li>Validation outputs (where applicable)  </li> <li>A Croissant metadata file for interoperability via Hugging Face</li> </ul> <p>Supporting Documentation</p> <p>All datasets include source article lists, annotation guidelines, and usage notes.</p>"},{"location":"overview/datasets_description.html#summary-table-of-datasets","title":"Summary Table of Datasets","text":"Dataset Name Domain Records Modalities Expert Validation Link Cytotoxicity Nanomaterials 5535 Text, tables, figures \u2705 Learn more SelTox Nanomaterials 3286 Text, tables, figures \u2705 Learn more Synergy Nanomaterials 3226 Text, tables, diagrams \u2705 Learn more Nanozymes Nanomaterials 1133 Text, diagrams \u2705 Learn more Magnetic nanomaterials Nanomaterials 2579 Text, tables \u2705 Learn more Benzimidazoles Small molecules 1721 SMILES, numeric values \u2705 Learn more Oxazolidinones Small molecules 3103 SMILES, numeric values \u2705 Learn more Chelate Complexes Small molecules 907 SMILES, lgK \u2705 Learn more Eye Drops Small molecules 163 SMILES, permeability \u2705 Learn more Photostability Small molecules 70 SMILES, photostability \u2705 Learn more"},{"location":"overview/datasets_description.html#how-to-use-the-datasets","title":"How to Use the Datasets","text":"<p>The CDEB datasets support a variety of research and development workflows:</p> <ul> <li>Training and evaluating information extraction systems (e.g., LLMs, OCR, image-text models)  </li> <li>Developing QSAR models and exploring structure\u2013property relationships  </li> <li>Benchmarking multimodal AI for chemistry-focused applications  </li> <li>Supporting tasks in materials design, drug discovery, and toxicity prediction</li> </ul> <p>Benchmark Usage</p> <p>These datasets are already being used to evaluate state-of-the-art models on real-world chemical extraction tasks.</p>"},{"location":"overview/datasets_description.html#access-to-the-datasets","title":"Access to the Datasets","text":"<p>You can access the datasets via:</p> <ul> <li>Hugging Face Datasets Hub </li> <li>The GitHub repository </li> <li>Direct downloads (CSV/Parquet)  </li> <li>An upcoming PyPI Python package for programmatic access</li> </ul> <p>Croissant Files</p> <p>Hugging Face releases include Croissant metadata files for structured dataset interoperability and schema validation.</p>"},{"location":"overview/datasets_description.html#example-of-loading-a-dataset-in-python","title":"Example of Loading a Dataset in Python","text":"<pre><code>import pandas as pd\n\n# Direct link to Parquet file\nparquet_url = \"https://huggingface.co/datasets/ai-chem/Nanozymes/resolve/main/data/train-00000-of-00001.parquet\"\n\n# Loading with pandas and pyarrow\ndf = pd.read_parquet(parquet_url, engine=\"pyarrow\")\n\ndf.head()\n</code></pre>"},{"location":"overview/datasets_description.html#summary","title":"Summary","text":"<ul> <li>CDEB provides a multimodal benchmark covering key chemical subfields  </li> <li>Datasets are expert-validated and rich in metadata  </li> <li>Designed for reproducible, scalable training and evaluation of AI models in chemistry  </li> <li>Fully documented and accessible through open platforms</li> </ul>"},{"location":"overview/project_motivation.html","title":"Project Motivation","text":""},{"location":"overview/project_motivation.html#problem","title":"Problem","text":"<p>Advances in chemistry and materials science increasingly depend on the ability to extract structured data from the vast body of scientific literature. However, much of this information remains embedded in unstructured formats \u2014 such as free text, complex tables, and visual figures \u2014 making it difficult to reuse for computational analysis.</p> <p>Manual data extraction is:</p> <ul> <li>Labor-intensive and slow </li> <li>Prone to inconsistencies and human error </li> <li>Unscalable for the growing volume of publications </li> </ul> <p>Traditional NLP tools, often trained on general or biomedical corpora, struggle with the domain-specific syntax and semantics of chemistry. Moreover, most existing tools are text-focused and cannot access information presented in other modalities like chemical diagrams, plots, and structured tables, which are critical in chemical reporting.</p>"},{"location":"overview/project_motivation.html#relevance","title":"Relevance","text":"<p>This is a central challenge for the research community because:</p> <ul> <li>Reliable machine learning models require structured, domain-specific data </li> <li>Scientific progress is limited by the speed and accuracy of data curation </li> <li>Multimodal content \u2014 a hallmark of chemistry publications \u2014 requires models that can interpret and align information across text, tables, and images</li> </ul> <p>Recent progress in large language models (LLMs) and multimodal transformers has shown potential, but these models often underperform in chemical contexts due to:</p> <ul> <li>Lack of fine-grained benchmark datasets  </li> <li>Inadequate multimodal training data  </li> <li>The absence of standardized evaluation protocols  </li> </ul>"},{"location":"overview/project_motivation.html#goals-and-objectives","title":"Goals and Objectives","text":"<p>The central goal of CDEB is to create a comprehensive, expert-validated benchmark for chemical information extraction, enabling the development and assessment of AI systems across multiple chemical domains.</p> <p>To accomplish this, the project aims to:</p> <ul> <li>\u2705 Collect and annotate 10 datasets from published chemical literature  </li> <li>\u2705 Capture multimodal representations \u2014 including text, tables, figures, and chemical structures  </li> <li>\u2705 Apply rigorous expert validation to ensure annotation quality and consistency  </li> <li>\u2705 Establish standardized evaluation metrics for benchmarking model performance  </li> <li>\u2705 Support reproducibility and transparency through detailed documentation and metadata  </li> </ul> <p>By addressing the lack of multimodal benchmarks in chemistry, CDEB provides a foundation for robust, scalable, and trustworthy AI tools that can transform scientific discovery in chemistry and materials science.</p>"}]}